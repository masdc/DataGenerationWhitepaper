{"cells":[{"cell_type":"code","source":["# install the dbldatagen library\n","%pip install dbldatagen\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"b495a09f-686c-4e6d-b68b-33cc8662f867","statement_id":10,"state":"finished","livy_statement_state":"available","queued_time":"2023-10-09T17:09:09.2155797Z","session_start_time":null,"execution_start_time":"2023-10-09T17:09:24.3749894Z","execution_finish_time":"2023-10-09T17:09:26.2482438Z","spark_jobs":{"numbers":{"SUCCEEDED":0,"FAILED":0,"UNKNOWN":0,"RUNNING":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"1a1d1b79-f923-4e2e-9faa-e7c9af884c84"},"text/plain":"StatementMeta(, b495a09f-686c-4e6d-b68b-33cc8662f867, 10, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":3,"data":{},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting dbldatagen\n  Downloading dbldatagen-0.3.5-py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.3/86.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: dbldatagen\nSuccessfully installed dbldatagen-0.3.5\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/nfs4/pyenv-e563d8d2-3f57-4893-8dbd-ef3656be4d08/bin/python -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n"]},{"output_type":"execute_result","execution_count":3,"data":{},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Warning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":3,"metadata":{},"id":"8f4ec457-c13c-48fc-ae04-f18cd3ce1a74"},{"cell_type":"code","source":["# First Synthetic data generation example\n","\n","import dbldatagen as dg #import the library\n","from pyspark.sql.types import IntegerType, FloatType, StringType  #use sql types to define the type of the columns.\n","\n","\n","\n","ds = (dg.DataGenerator(spark, name=\"test_data_set1\", rows=10,partitions=4) #10 rows of data\n","                            .withIdOutput() #Create an ID Column\n","                            .withColumn(\"code1\", IntegerType(), minValue=100, maxValue=200) #create a column named \"code1\" of Integer Type, with values from 100 to 200\n","                            .withColumn(\"code2\", IntegerType(), minValue=0, maxValue=10) #create a column named \"code2\" of Integer Type, with values from 0 to 20\n","                            )\n","                            \n","df = ds.build() #here the data is actually generated and the DataFrame is built\n","df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"Example1\") #save the DataFrame as a Table in the Lakehouse"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"b495a09f-686c-4e6d-b68b-33cc8662f867","statement_id":19,"state":"finished","livy_statement_state":"available","queued_time":"2023-10-09T17:09:09.3417293Z","session_start_time":null,"execution_start_time":"2023-10-09T17:09:47.7097361Z","execution_finish_time":"2023-10-09T17:10:12.559668Z","spark_jobs":{"numbers":{"SUCCEEDED":0,"FAILED":0,"UNKNOWN":0,"RUNNING":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"81fc18f5-cd71-4c98-9937-1be22c6bcf14"},"text/plain":"StatementMeta(, b495a09f-686c-4e6d-b68b-33cc8662f867, 19, Finished, Available)"},"metadata":{}}],"execution_count":5,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"2a1eed6c-5844-4d4e-a565-a3b3b3fe71dc"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","display_name":"Synapse PySpark"},"microsoft":{"host":{"synapse_widget":{"token":"9008748a-eff6-4d55-8563-7c45d86917a8","state":{}}},"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"trident":{"lakehouse":{"known_lakehouses":[{"id":"aa79825f-52d4-4b66-8452-34ede639ba5d"}],"default_lakehouse":"aa79825f-52d4-4b66-8452-34ede639ba5d","default_lakehouse_name":"msdatatesting","default_lakehouse_workspace_id":"2249f67c-347d-4752-b453-ff5473c55ff3"}}},"nbformat":4,"nbformat_minor":5}